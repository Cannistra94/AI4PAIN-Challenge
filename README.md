# AI4PAIN-Challenge
Code and models developed for the Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN 2025), focusing on multimodal physiological signal classification (EDA, BVP, RESP, SpO‚ÇÇ) for automated pain detection.

This repository demonstrates our contribution to advancing AI-driven pain assessment and reflects participation in an international competition (Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN 2025) (https://sites.google.com/view/ai4pain2025/home))
aimed at shaping next-generation healthcare solutions.

The challenge focuses on automated pain detection using multimodal physiological signals, including:

- Electrodermal Activity (EDA)
- Blood Volume Pulse (BVP)
- Respiratory (RESP)
- Peripheral Oxygen Saturation (SpO‚ÇÇ)

Pain is inherently subjective and often difficult to measure objectively. Traditional self-report methods are limited by communication barriers and variability in pain perception. 
This project explores the integration of signal processing, feature engineering, and machine learning (ML)/ deep learning (DL) to build robust models capable of providing objective pain assessments
aiming to improve clinical decision-making and patient care.

üîç Key Features
- Preprocessing pipelines for cleaning and aligning multimodal physiological data
- Feature extraction from time, frequency, and non-linear domains
- Implementation of various ML and DL models for three-class classification tasks for discriminating rest vs no-pain vs high-pain.
- Evaluation using standardized metrics provided by the AI4PAIN 2025 organizers
- Focus on interpretability to ensure clinical relevance

